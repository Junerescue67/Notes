<div align="center"><img src = "./../pics/OSoverall.png"></div>

# 进程
## 进程状态

<div align="center"><img src = "./../pics/process_state.png"></div>

## 进程控制块PCB


<table border = "true" align = "center">
    <tr>
        <td>进程状态</td>
    </tr>
    <tr>
        <td>进程编号</td>
    </tr>
    <tr>
        <td>程序计数器</td>
    </tr>
    <tr>
        <td>寄存器</td>
    </tr>
    <tr>
        <td>内存界限</td>
    </tr>
    <tr>
        <td>打开文件列表</td>
    </tr>
    <tr>
        <td>...</td>
    </tr>
</table>

<ul>
<li>进程状态:状态包括new,ready,running,waiting,terminated等
<li>程序计数器:计数器表示进程要执行的下个指令地址
<li>CPU寄存器:
<li>CPU调度信息:进程优先级、调度队列的指针和其他调度参数
<li>内存管理信息:根据操作系统所使用的的内存系统，包括基址和界限寄存器的值、页表和段表
</ul>

## 进程生成
<div align="center"><img src = "./../pics/process_create.png"></div>

子进程，系统调用fork()的返回值为0，而对于父进程，返回值为子进程的标识符

### 僵尸进程和孤儿进程
<ul>
<li>一般情况下，子进程是由父进程创建，而子进程和父进程的退出是无顺序的，两者之间都不知道谁先退出。正常情况下父进程先结束会调用 wait 或者 waitpid 函数等待子进程完成再退出，而一旦父进程不等待直接退出，则剩下的子进程会被init(pid=1)进程接收，成会孤儿进程。（进程树中除了init都会有父进程）。
<li>如果子进程先退出了，父进程还未结束并且没有调用 wait 或者 waitpid 函数获取子进程的状态信息，则子进程残留的状态信息（ task_struct 结构和少量资源信息）会变成僵尸进程。
子进程退出时向父进程发送SIGCHILD信号，父进程处理SIGCHILD信号。在信号处理函数中调用wait进行处理僵尸进程。<br>
原理是将子进程成为孤儿进程，从而其的父进程变为init进程，通过init进程可以处理僵尸进程。
</ul>

### 守护进程是什么？怎么实现？
>守护进程（Daemon）是运行在后台的一种特殊进程。它独立于控制终端并且周期性地执行某种任务或等待处理某些发生的事件。守护进程是一种很有用的进程。

#### 守护进程特点
<ul>
<li>守护进程最重要的特性是后台运行。
<li>守护进程必须与其运行前的环境隔离开来。这些环境包括未关闭的文件描述符，控制终端，会话和进程组，工作目录以及文件创建掩模等。这些环境通常是守护进程从执行它的父进程（特别是shell）中继承下来的。 
<li>守护进程的启动方式有其特殊之处。它可以在Linux系统启动时从启动脚本/etc/rc.d中启动，可以由作业规划进程crond启动，还可以由用户终端（shell）执行。
</ul>

#### 实现
<ol>
<li>在父进程中执行fork并exit推出；
<li>在子进程中调用setsid函数创建新的会话；
<li>在子进程中调用chdir函数，让根目录 ”/” 成为子进程的工作目录；
<li>在子进程中调用umask函数，设置进程的umask为0；
<li>在子进程中关闭任何不需要的文件描述符
</ol>

## 进程通信
<ul>
<li>如果一个进程不能影响其他进程或被其他进程所影响，那么该进程是独立的
<li>如果一个进程能影响其他进程或被其他进程所影响，那么该进程是协作的
</ul>

协作进程需要一种进程间通信机制（interprocess communication，IPC）
### 进程间通信的基本模式
<ul>
<li>共享内存
<li>消息传递
</ul>

### 共享内存系统
>建立共享内存区域
#### 生产者-消费者问题

### 消息传递系统
<ul>
<li>直接或间接通信<br>
<ul>
<li>直接通信</li>
需要通信的每个进程必须明确地命名通信的接收者和发送者
<ul>
<li>send(P,message):发送消息到进程P
<li>receive(Q,message):接收来自进程Q的消息
</ul>
属性
<ul>
<li>在需要通信的每对进程之间自动建立线路
<li>一条线路只能与两个进程相关联
<li>每队进程之间只有一条线路
</ul>

缺点：限制进程定义的模块化，不利于维护（硬编码）
<li>间接通信</li>
通过邮箱或端口来发送接收消息
<ul>
<li>send(A,message):发送消息到邮箱A
<li>receive(A,message):接收来自邮箱A的消息
</ul>
属性
<ul>
<li>只有在两个进程共享一个邮箱时，才能建立通信线路
<li>一条线路可以与两个或更多的进程相关联
<li>两个通信进程之间可有多个不同的线路，每个线路对应一个邮箱
</ul>
</ul>
<li>同步或异步通信
<li>自动或显式缓冲
</ul>

### IPC系统实例

#### POSIX共享内存
<ol>
    <li>调用共享内存:</li>
    segment_id = shmget(IPC_PRIVATE,size,S_IRUSR|S_IWUSR)<br>
    第一个参数：共享内存关键字（标识符）。IPC_PRIVATE生成一个新的共享内存段<br>
    第二个参数：共享内存段的大小<br>
    第三个参数：模式是读或写<br>
    <li>访问共享内存:</li>
    shared_memory = (char*)shmat(id,NULL,0)<br>
    sprintf(shared_memory,"Write to shared memory")<br>
    第一个参数：共享内存关键字（标识符）<br>
    第二个参数：内存中的指针位置。NULL，系统为用户选择位置<br>
    第三个参数：模式是读或写<br>
    <li>分离共享内存:</li>
    shmdt(shared_memory)<br>
    <li>删除共享内存:</li>
    shmctl(segment_id,IPC_RMID,NULL)<br>
</ol>

#### Mach
#### Windos

### 客户机-服务器系统通信

#### Socket
#### RPC
#### RMI

## 线程
<div align="center"><img src = "./../pics/thread.png" width="300"></div>

### 优点
<ul>
    <li>响应度高
    <li>资源共享
    <li>节省资源
    <li>多处理器体系结构的利用
</ul>

### 模型
<ul>
<li>多对一模型
<li>一对一模型
<li>多对多模型
</ul>

### 设计一个线程池，内存池
<ul>
<li>为什么需要线程池</li>

大多数的网络服务器，包括Web服务器都具有一个特点，就是单位时间内必须处理数目巨大的连接请求，但是处理时间却是比较短的。在传统的多线程服务器模型中是这样实现的：一旦有个请求到达，就创建一个新的线程，由该线程执行任务，任务执行完毕之后，线程就退出。这就是”即时创建，即时销毁”的策略。尽管与创建进程相比，创建线程的时间已经大大的缩短，但是如果提交给线程的任务是执行时间较短，而且执行次数非常频繁，那么服务器就将处于一个不停的创建线程和销毁线程的状态。这笔开销是不可忽略的，尤其是线程执行的时间非常非常短的情况。
<li>线程池原理</li>
在应用程序启动之后，就马上创建一定数量的线程，放入空闲的队列中。这些线程都是处于阻塞状态，这些线程只占一点内存，不占用CPU。当任务到来后，线程池将选择一个空闲的线程，将任务传入此线程中运行。当所有的线程都处在处理任务的时候，线程池将自动创建一定的数量的新线程，用于处理更多的任务。执行任务完成之后线程并不退出，而是继续在线程池中等待下一次任务。当大部分线程处于阻塞状态时，线程池将自动销毁一部分的线程，回收系统资源。
<li>线程池的作用</li>
需要大量的线程来完成任务，且完成任务的时间比较短；对性能要求苛刻的应用；对性能要求苛刻的应用
<li>内存池的原理</li>
在软件开发中，有些对象使用非常频繁，那么我们可以预先在堆中实例化一些对象，我们把维护这些对象的结构叫“内存池”。在需要用的时候，直接从内存池中拿，而不用从新实例化，在要销毁的时候，不是直接free/delete，而是返还给内存池。把那些常用的对象存在内存池中，就不用频繁的分配/回收内存，可以相对减少内存碎片，更重要的是实例化这样的对象更快，回收也更快。当内存池中的对象不够用的时候就扩容。可以避免频繁内核和用户态交换数据
<li>内存池的优缺点</li>
内存池对象不是线程安全的，在多线程编程中，创建一个对象时必须加锁。

## CPU调度

### 调度准则
<ul>
<li>CPU使用率
<li>吞吐量
<li>周转时间
<li>等待时间
<li>响应时间
</ul>

### 调度算法
<ul>
<li>先来先服务
<li>最短作业优先
<li>优先级调度
<li>时间片轮转
<li>多级队列
</ul>

## 进程同步

### 临界区
>对共享内存进行访问的代码片段
#### 条件
<ul>
<li>互斥</li>
实现互斥的方式
<ul>
<li>屏蔽中断
<li>加锁
</ul>
Peterson算法
TSL指令
SCHG指令
<li>前进
<li>有限等待
</ul>

### 信号量
>wait() signal() (P/V)

<ul>
<li>计数
<li>二进制0/1 mutex
</ul>

### 管程
>类型或抽象数据类型，封装了私有数据类型及操作数据的公有方法<br>
确保一次只有一个进程在管程内活动

## 死锁
### 必要条件
<ul>
<li>互斥
<li>循环等待
<li>忙则等待
<li>不可抢占
</ul>

### 死锁预防
破坏四个必要条件

### 从死锁中恢复

<li>通过抢占进行恢复</li>
在某些情况下，可能会临时将某个资源从它的持有者转移到另一个进程。比如在不通知原进程的情况下，将某个资源从进程中强制取走给其他进程使用，使用完后又送回。这种恢复方式一般比较困难而且有些简单粗暴，并不可取。

<li>通过回滚进行恢复</li>
如果系统设计者和机器操作员知道有可能发生死锁，那么就可以定期检查流程。进程的检测点意味着进程的状态可以被写入到文件以便后面进行恢复。检测点不仅包含存储映像(memory image)，还包含资源状态(resource state)。一种更有效的解决方式是不要覆盖原有的检测点，而是每出现一个检测点都要把它写入到文件中，这样当进程执行时，就会有一系列的检查点文件被累积起来。

为了进行恢复，要从上一个较早的检查点上开始，这样所需要资源的进程会回滚到上一个时间点，在这个时间点上，死锁进程还没有获取所需要的资源，可以在此时对其进行资源分配。

<li>杀死进程恢复</li>
最简单有效的解决方案是直接杀死一个死锁进程。但是杀死一个进程可能照样行不通，这时候就需要杀死别的资源进行恢复。

另外一种方式是选择一个环外的进程作为牺牲品来释放进程资源。


### 死锁避免
#### 俺安全状态
>如果OS能按某个顺序为每个进程分配资源并能避免死锁，那么OS状态就是安全的

安全状态不是死锁状态，死锁状态是不安全状态

#### 银行家算法
<ol>
<li>如果Request<=Need,转到2；否则出错</li>
<li>如果Request<=Available,转到3；否则等待</li>
<li>分配资源</li>
Available = Available - Request<br>
Allocation = Allocation + Request<br>
Need = Need - Request<br>
</ol>

## 内存管理
>CPU能访问的存储器只有内存和处理器内的寄存器

>内存空间保护是通过CPU硬件对用户模式所产生的的每一个地址与寄存器的地址进行比较来完成的<br>只有操作系统可以通过特殊指令来加载基址寄存器和界限地址寄存器

### 交换
>进程需要在内存中以便执行。进程也可以暂时从内存中交换到备份存储上，当执行时再调回

>这种交换策略的变种被用在基于优先级的调度算法中。交换有时称为roll out/roll in
- 备份存储通常为足够大的快速磁盘，以容纳所有用户程序的内存镜像副本、并提供对内存镜像的直接访问。交换系统上下文切换时间较长，为有效使用 CPU，通常使每个进程每次执行获取的时间片比交换时间长。
- 为了 **只交换用户进程真正使用的内存空间** （如一个用户进程当前可能只使用了 10MB，但其最多可能使用 200 MB），用户进程需要告诉系统其内存需求情况以减少交换时间。
- 换出进程时，进程必须完全处于空闲状态。考虑如下场景：一个正在等待 I/O 操作的进程 P 即将被换出，若 I/O 操作异步访问 P 进程内存中的缓冲区，或是 I/O 设备正忙，I/O 操作在排队等待，此时换出进程 P，换入进程 P’ 会导致 I/O 操作已经属于 P’ 的内存。解决方案：
  - 不能换出有待处理 I/O 的进程
  - I/O 操作只能使用操作系统缓冲区，仅当进程在内存中执行时才发生操作系统缓冲和进程内存缓冲之间的数据转移
- 上述标准交换在目前的操作系统中使用不广泛，交换需要很长时间并且只能提供很少的执行时间。对上述交换方式的一种修正在很多 UNIX 系统中得到使用：当且仅当系统负荷过高，内存吃紧时进行交换。早期缺乏高级硬件的个人计算机通过此种交换可同时运行多个进程，如 MS Windows 3.1，该系统内存不足时将老进程交换到磁盘上，当且仅当用户再次选择执行该进程时才再次换入。

### 逻辑地址和物理地址

- CPU 生成的地址为 **逻辑地址（logical address）** ，加载到 **内存地址寄存器（memory-address register）** 中的地址为 **物理地址（physical address）** 。编译时和加载时的地址绑定方法生成的逻辑地址和物理地址相同，执行时的地址绑定方案生成的逻辑地址和物理地址不同。通常称逻辑地址为 **虚拟地址（virtual address）** 。
- **逻辑地址空间（logical address space）** 为由程序所生成的所有逻辑地址的集合， **物理地址空间（physical address space）** 为与这些逻辑地址对应的物理地址集合。
- 运行时从虚拟地址到物理地址的映射由硬件设备 **内存管理单元（memory-management unit，MMU）** 完成。一个最简单的 MMU 方案是将用户进程产生的地址加上 **重定位寄存器（relocation register）** 的值作为最终的物理内存地址。
- 用户进程绝不会看到真正的物理地址，一个地址在内存中比较、使用均基于虚拟地址，只有该地址作为内存地址，如执行加载/存储时才需要做到物理空间的地址映射。总而言之，用户进程只产生逻辑地址，且认为地址空间从 0 开始，而使用对应内存地址前必须由 MMU 做物理地址映射。

### 动态加载、链接与共享库

- **动态加载（dynamic loading）** ：所有子程序均以可重定位的方式保存在磁盘上，仅主程序装入内存并执行，当且仅当某个子程序被需要时才会装载进内存。此种方法设计程序主要是用户程序开发者的责任。其优势在于不被使用的子程序绝不会加载，若程序中有较多代码用于处理异常，动态加载会特别有效。
- **动态链接库（dynamically linked library）** ：部分操作系统只支持 **静态链接（static linking）** ，即加载程序将操作系统提供的语言库与其他目标模块一起合并到最终的二进制程序镜像中，所有程序均有一份所需系统库的副本；而动态链接将系统库的加载延迟到运行时，用户程序对系统库的引用留有 **存根（stub）** ，存根指用于定位内存驻留库程序的一小段代码。当执行存根时，若所需的系统库已经驻留在内存中，则存根使用已有的系统库，否则将系统库装入内存。最终存根均会将系统库地址替换自身并执行系统库，此时所有使用某个库的进程只需要一个库代码副本。
- 动态链接为库更新带来方便，库版本更新后，引用该库的程序会自动使用新版本而无需重新链接。多个版本的库也可以同时装入内存，程序根据自己所需的版本信息确定使用哪个副本。此类系统也称为 **共享库（shared libraried）** 。
  
### 连续内存分配
#### 内存保护

- 内存分为操作系统驻留区域和用户进程驻留区域，操作系统通常位于低内存（因为中断向量通常位于低内存）。 **连续内存分配（contiguous memory allocation）** 可使内存中每个进程占有连续的内存区域。
- 通过重定位寄存器和界限地址寄存器可实现内存保护，重定位寄存器含有最低 *物理地址* 值，界限地址寄存器含有 *逻辑地址* 的范围值。重定位寄存器机制也允许操作系统动态改变，若某操作系统服务（如某个驱动程序）不常使用，则内存中不必保留其代码和数据，这类代码称为 **暂时（transient）** 操作系统代码，它们根据需要调入/调出，可在程序执行时动态改变操作系统大小。重定位寄存器和界限地址寄存器的硬件支持如下图所示。

![rlreg_limitreg](./../pics/rlreg_limitreg.png)

#### 内存分配

- 最简单的内存分配方法：将内存分为多个 **固定** 大小的 **分区（partition）** ，每个分区只能容纳一个进程，多道程序的程度受分区数限制。当一个分区空闲时可以从输入队列选择一个进程调入空闲分区，进程终止时释放该分区。此种方式最初被 MFT（F：Fixed，IBM OS/360）使用，目前已被淘汰。

- 对 MFT 的推广是 MVT（V:Variable），即 **可变分区（variable partition）** 方案。操作系统维护一个表以记录哪些内存可用和哪些内存已被占用。初始时所有内存均可用于用户进程，可视作一大块可用内存，称为 **孔（hole）** 。新进程到来时需要查找足够大的孔，并从该孔为进程分配所需内存，孔内剩余内存可分配给其他进程。随着进程的到来和离开，内存中会分散着大小不同的孔。进程终止时释放的内存会形成新孔，若新孔和其他孔相邻，则这些相邻的孔可以合并为一个大孔。此时系统可以检查是否有进程在等待分配内存空间，以及新合并的内存空间是否满足该进程的需求。

- 上述 MVT 方法是通用动态存储分配问题（dynamic storage allocation problem）
   的一种情况，从内存中的一组孔中选择一个空闲孔有如下三种常用方法，其中执行时间、空间利用方面最差适应方法最差，空间利用方面首次适应和最佳适应相近，但首次适应更快：

  - **首次适应（First fit）** ：分配寻找到的第一个足够大的孔，查找可以从任何位置（如内存开始位置或上次首次适应结束的位置）开始，一旦找到足够大的空闲孔就停止；
  - **最佳适应（Best fit）** ：分配 *最小* 的足够大的孔，此方式必须查找整个表（若表内孔位置记录按孔的大小排序则不需要查找整个表）；
  - **最差适应（Worst fit）** ：分配 *最大* 的孔，同样需要查找整个表，产生的孔比最佳适应方法产生的孔价值更大。

### 碎片

- 首次适应方法和最佳适应方法都有外部碎片问题。随着进程装入和移出内存，空闲内存空间被分为散落的小段，产生 **外部碎片问题（external fragmentation）** ：所有可用内存空间之和满足一个/多个进程的请求，但这些可用内存并不连续。上述首次适应和最佳适应两种不同方法导致的碎片的数量也不同，对于不同的系统两者各有优劣，分配方向（从空闲块的顶端还是模块开始分配内存）也会对碎片数量产生影响。
- **50% 规则** ：对采用首次适应方法的统计表明，假定有 N 个块已被分配，无论采用什么优化，都可能有 0.5N 个块为外部碎片，即 1/3 的内存无法被使用。
- 维护一个小孔的开销比小孔本身可能更大，例如一个需要 2046B 空间的进程被分配了大小为 2048B 的孔，剩余的 2B 小孔维护的开销比 2B 大得多。因此通常采用 *固定大小的块* 而不是字节作为分配单元。此时进程被分配的空间通常大于所需空间，分配给进程的块中使用不到的空间被称为 **内部碎片（internal fragmentation）** 。
- 解决外部碎片问题的方法：
  - **紧缩（compaction）** ：移动内存内容使所有空闲空间合并为一整块。紧缩仅可在重定位是动态的、且在运行时重定位的情况下可用。紧缩根据采用的合并算法不同，需要的开销大小也不同，最简单的合并算法将所有进程移动到内存的一端，空闲的孔移动到内存另一端以生成大孔，其开销较大；
  - 允许一个进程占有的内存地址空间非连续，只要有物理内存就可以为进程分配：分页、分段、分段+分页。

### 分页方法

- 将物理内存分为固定大小的块，称为 **帧（frame）** ，将逻辑内存分配同样大小的块，称为 **页（page）** 。备份存储页分为同样固定大小的块，进程执行时将执行所需的页从备份存储中调入可用的内存帧中。其硬件支持如下图所示。
![img](./../pics/hardware-support-for-pages.jpg)
- CPU 生成的每个逻辑地址分为两部分： **页号（page number）** 和 **页偏移（page offset）** ，记为 `p` 和 `d` 。页号为 **页表（page table）** 的索引，页表包含每页位于物理内存的基地址，页 `p` 在页表中对应的基地址加上页偏移量 `d` 即为该逻辑地址映射的物理地址。
- 页大小由硬件决定，通常为 2 的次幂，根据计算机结构不同，每页大小从 512B ~ 16MB 不等。页大小为 2 的幂可直接将逻辑地址的 2 进制表示划分为 `p` 和 `d`。
- 分页也是一种动态重定位，每个逻辑地址由分页硬件绑定为对应的物理地址。采用分页技术不会产生外部碎片，但可能有内部碎片（进程所需内存不足一页，或要求的内存大小不是页的整数倍则最后一帧有内存空闲）。
- 目前页大小通常为 4 ~ 8KB，有的系统支持更大页，有的 CPU 内核支持多种页大小。页的大小受如下因素制约：
  - 在进程大小和页大小无关的前提下，可以假设每个进程平均有半页内部碎片，因此更小的页会带来更少的内部碎片；
  - 页表对于页和物理内存中的帧的对应关系记录需要一定开销，并且该开销随着页大小的增大而减小，页表中每个条目通常占 4B（可变）。
- 分页的重要特点是 *用户视角内存* 和 *实际物理内存* 的分离，通过地址转换硬件将用户视角下的逻辑地址转换为物理地址。用户程序将内存作为一整块处理，而实际物理内存中进程可能分布在各个独立的帧中。用户进程无法访问其页表规定之外的内存，进程可见的页表仅包含进程拥有的页面记录。
- 操作系统使用 **帧表（frame table）** 维护物理内存的分配细节（已被占用的帧、可用帧等），帧表的每个条目对应一帧，并标明该帧是否空闲，若占用则被哪个（些）进程的哪个页占用等。操作系统同时 **为每个进程维护一个页表的副本** ，当一个进程可被分配 CPU 时，CPU 调度程序可根据该副本定义硬件页表（用户进程运行在用户模式，若进行系统调用，操作系统需要使用进程的页表副本来获取进程逻辑地址映射的物理地址）。

### 硬件支持

- 最简单的页表硬件实现方法将页表作为一组专用寄存器。

- 当代计算机允许页表非常大，因此页表放置在内存中，并设置 **页表基寄存器（page-table base register，PTBR）** 指向页表，改变页表的位置仅需要修改此寄存器。此种做法的缺陷在于访问一个字节需要两次内存访问（一次用于在内存的页表中查找页号对应的条目，一次用于获取目标字节）。

- 转换表缓冲区（translation look-aside buffer，TLB） 
  是针对上述问题的专用快速硬件缓冲（关联存储器），其条目由键和值组成。TLB 查找速度快且造价昂贵，通常仅有 64 ~ 1024 个条目。TLB 和页表一起使用时，TLB 仅包含最近使用过的页表条目，查询流程如下：

  - CPU 产生逻辑地址，从逻辑地址提取出页号交付 TLB，TLB 将页号和存储的键比对，若寻找到相同键则结束流程；
  - 请求的页码不在 TLB 中，即 **TLB 失效（TLB miss）** ，此时需要在页表中查询。在页表中查询到与页号对应的帧号后，将页号和帧号增加到 TLB 中。若 TLB 中条目已满，则操作系统使用某种策略替换掉已有的一个条目，例如 *最近最少使用替换（LRU）* 或随机替换等。TLB 中有的条目是永久驻留的（不允许从 TLB 中被替换），通常内核代码在 TLB 中的条目固定。

- 有的 TLB 在每个 TLB 条目中存储了 **地址空间标识符（address-space identifier，ASID）** ，该项用于唯一标识进程，为进程提供地址空间保护。TLB 解析虚拟页号时必须确保当前运行进程的 ASID 和 TLB 中条目对应的 ASID 匹配，否则视作 TLB 失效。除了内存空间保护，ASID 还使 TLB 能够同时包含多个不同进程的记录。如果 TLB 不支持每个条目有独立的 ASID，那么一旦有新页表被选择（例如进程的换入/换出），TLB 就需要被全部 **刷新（flushed）** 或删除，防止 TLB 中存在无效的条目（页号地址无效的条目，如上一个进程留下来的无效物理地址）导致被换入的进程使用错误的地址转换。

- 页号在 TLB 中被查找到的百分比为 **命中率（hit ratio）** ， **有效内存访问时间（effective memory-access time）** 的计算需要根据 TLB 的命中率加权。例如查找 TLB 需要 20ns，内存访问需要 100ns，命中率 80%，则有效内存访问时间为 `0.8 x 120 + 0.2 x 220 = 140ns` 。需要注意的是， **TLB 查询早于内存中页表的查询，只有 TLB 查询结束并且没有查询到帧号时才会开始在页表中的查询** ，此前计算机组成原理中讲过的 TLB 有错误。